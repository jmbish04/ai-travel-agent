# AI Cascade Strategy - General Strategy

## General Cascade Principle

**Fast Methods â†’ LLM â†’ Fallback**

1. **Fast Methods** (NLP/Transformers/Heuristics) - for simple cases
2. **LLM** - for complex cases and contextual processing
3. **Fallback** - for cases when nothing worked

## Adapting Cascade to Task

### ğŸ¯ Entity Extraction
```
NER/Transformers â†’ Heuristics â†’ LLM â†’ Regex Fallback
```
- **NER**: Extracts basic entities (LOC, DATE, MONEY, PERSON, ORG)
- **Heuristics**: Generates candidates from patterns (capitalization, sequences)
- **LLM**: Resolves ambiguities and context
- **Fallback**: Simple regex for known patterns

### ğŸ“‹ Content Classification
```
Transformers â†’ LLM â†’ Rule-based Fallback
```
- **Transformers**: Fast classification by patterns
- **LLM**: Processing complex cases and context
- **Fallback**: Simple rules for obvious cases

### ğŸ¯ Intent Classification
```
Transformers â†’ LLM â†’ Keyword Fallback
```
- **Transformers**: Direct intent recognition
- **LLM**: Processing complex/composite queries
- **Fallback**: Keywords for basic intents

### ğŸ” Query Processing
```
Slot Memory â†’ LLM Router â†’ Pattern Matching
```
- **Slot Memory**: Using context from previous queries
- **LLM Router**: Complex routing considering history
- **Pattern Matching**: Simple rules for obvious cases

### ğŸŒ Search & Summarization
```
Query Optimization â†’ Search â†’ LLM Summarization â†’ Template Fallback
```
- **Query Optimization**: Improving query for search
- **Search**: Getting results
- **LLM Summarization**: Smart summarization with sources
- **Template Fallback**: Structured output without LLM

### âœ… Verification
```
Fact Checking â†’ LLM Audit â†’ Rule-based Validation
```
- **Fact Checking**: Checking facts against sources
- **LLM Audit**: Analyzing response quality
- **Rule-based**: Simple checks for compliance

## Cascade Selection Criteria

### When to use specific levels:

#### ğŸš€ Fast Methods (NLP/Transformers/Heuristics)
- âœ… High accuracy on simple cases
- âœ… Low latency
- âœ… Few resources (CPU/tokens)
- âœ… Deterministic result

#### ğŸ¤– LLM
- âœ… Complex logic/context
- âœ… Ambiguous cases
- âœ… Need user adaptation
- âœ… Need explanation/justification

#### ğŸ›¡ï¸ Fallback
- âœ… When LLM is unavailable
- âœ… For known patterns
- âœ… When deterministic result needed
- âœ… For critical cases

## Monitoring and Optimization

### Metrics to track:
- **Accuracy** by cascade levels
- **Response time** of each level
- **Usage frequency** of each level
- **Resources** (CPU, memory, tokens)

### Automatic optimization:
- Switching to LLM when fast method accuracy is low
- Caching results for repeating queries
- A/B testing different cascades

## Implementation Examples

### Entity Extraction for cities:
```
NER (LOC/GPE) â†’ Multi-word heuristics â†’ LLM disambiguation â†’ Regex patterns
```

### Content Classification:
```
Transformers zero-shot â†’ LLM context â†’ Keyword rules
```

### Intent Classification:
```
Transformers classification â†’ LLM complex cases â†’ Keyword matching
```